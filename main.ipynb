{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PRIMMDebug Log Data Analaysis Notebook\n",
    "This notebook displays all of the analysis of the log data that took place in the PRIMMDebug initial research paper.\n",
    "\n",
    "The log data was collected from five schools between December 2024-February 2025. It is divided into the following sections:\n",
    "1. **Summary statistics:** ...\n",
    "2. **Establishing variables:**...\n",
    "3. **Visualisation of variables:**...\n",
    "4. **Students' written responses:**...\n",
    "\n",
    "All you need to do is run the notebooks in order and the statistics that appear in the paper will be displayed. If there are any issues, please report them in the [Issues section of the GitHub repository](https://github.com/LaurieGale10/primmdebug-log-data-analysis/issues).\n",
    "\n",
    "Before we run anything else, let's first import all of the necessary files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from classes.ExerciseLog import ExerciseLog\n",
    "from classes.StageLog import StageLog\n",
    "from classes.StudentId import StudentId\n",
    "from classes.exercise_classes.Exercise import Exercise\n",
    "from classes.processors.ExerciseLogProcessor import ExerciseLogProcessor\n",
    "from classes.processors.StageLogProcessor import StageLogProcessor\n",
    "\n",
    "from loading_services.fetch_log_from_firebase import *\n",
    "from loading_services.fetch_logs_from_file import fetch_data_from_json\n",
    "\n",
    "from constants import *\n",
    "\n",
    "from loading_services.parse_logs import *\n",
    "import plotly.express as px\n",
    "import datetime\n",
    "\n",
    "exercises: list[Exercise] = parse_exercises(fetch_data_from_json(\"data/exercises\"))\n",
    "stage_logs: list[StageLog] = parse_stage_logs(fetch_data_from_json(\"data/stage_logs\"))\n",
    "exercise_logs: list[ExerciseLog] = parse_exercise_logs(stage_logs, fetch_data_from_json(\"data/exercise_logs\"))\n",
    "student_ids: list[StudentId] = parse_student_ids(fetch_data_from_json(\"data/student_ids\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary Statistics\n",
    "\n",
    "This data displays the following summary statistics to give information into the scale of the data we collected. We report below on:\n",
    "- Number of exercises (that contain at least one completed PRIMMDebug stage)\n",
    "  - Successful\n",
    "  - Unsuccessful\n",
    "  - Completed\n",
    "  - Per each PRIMMDebug challenge\n",
    "- Number of PRIMMDebug stages.\n",
    "- Number of students\n",
    "- Time of data collection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Number of attempted PRIMMDebug challenges: {len(exercise_logs)}\")\n",
    "\n",
    "number_successful_exercises: int = 0\n",
    "print(f\"- Number of PRIMMDebug challenges where students reported successfully resolving the error they contained: {number_successful_exercises}\")\n",
    "\n",
    "number_unsuccessful_exercises: int = 0\n",
    "print(f\"- Number of PRIMMDebug challenges where students did not report successfully resolving the error they contained: {number_unsuccessful_exercises}\")\n",
    "\n",
    "#TODO: This line is totally unreadable; make this a function in the ExerciseLogProcessor class\n",
    "number_completed_exercises: int = len([ExerciseLogProcessor.get_last_stage(exercise_log).stage_name for exercise_log in exercise_logs if ExerciseLogProcessor.get_last_stage(exercise_log) is not None and ExerciseLogProcessor.get_last_stage(exercise_log).stage_name == \"modify\"])\n",
    "print(f\"- Number of entirely completed PRIMMDebug challenges (where students reached the Make stage of PRIMMDebug): {number_completed_exercises}\\n\")\n",
    "\n",
    "challenge_attempts: dict[str] = {}\n",
    "for exercise_log in exercise_logs:\n",
    "    if exercise_log.exercise_name not in challenge_attempts:\n",
    "        challenge_attempts[exercise_log.exercise_name] = 1\n",
    "    else:\n",
    "        challenge_attempts[exercise_log.exercise_name] += 1\n",
    "challenge_attempts_fig = px.bar(x = challenge_attempts.keys(), y = challenge_attempts.values(), labels = {\"x\": \"Challenge Name\", \"y\": \"Frequency\"})\n",
    "challenge_attempts_fig.show()\n",
    "\n",
    "from collections import Counter\n",
    "challenge_end_stages: dict[str, int] = dict(Counter([ExerciseLogProcessor.get_last_stage(exercise_log).stage_name.name for exercise_log in exercise_logs if ExerciseLogProcessor.get_last_stage(exercise_log) is not None]))\n",
    "final_stage_fig = px.bar(x = list(challenge_end_stages.keys()), y = list(challenge_end_stages.values()), labels = {\"x\": \"Final stage of PRIMMDebug\", \"y\": \"Frequency\"})\n",
    "final_stage_fig.show()\n",
    "\n",
    "print(f\"Number of completed PRIMMDebug stages: {len(stage_logs)}\")\n",
    "\n",
    "print(f\"Number of participating students: {len(student_ids)}\")\n",
    "\n",
    "gender_split_fig = px.bar(x = get_gender_split().keys(), y = get_gender_split().values(), labels = {\"x\": \"Gender\", \"y\": \"Frequency\"})\n",
    "gender_split_fig.show()\n",
    "\n",
    "year_group_split_fig = px.bar(x = get_year_group_split().keys(), y = get_year_group_split().values(), labels={\"x\": \"Year Group\", \"y\": \"Frequency\"})\n",
    "year_group_split_fig.show()\n",
    "\n",
    "school_split_fig = px.bar(x = get_school_split().keys(), y = get_school_split().values(), labels={\"x\": \"School\", \"y\": \"Frequency\"})\n",
    "school_split_fig.show()\n",
    "\n",
    "exercises_per_student: dict[str, int] = {}\n",
    "for exercise in exercise_logs:\n",
    "    student_id: str = exercise.student_id\n",
    "    exercises_per_student[student_id] = exercises_per_student.get(student_id) + 1 if student_id in exercises_per_student else 1\n",
    "\n",
    "attempted_challenges_per_student_fig = px.histogram(exercises_per_student.values(), marginal=\"box\")\n",
    "attempted_challenges_per_student_fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Establishing Variables\n",
    "Now we move onto introducing the variables that underpin our log data analysis. These include:\n",
    "- Time taken\n",
    "  - Per challenge attempt\n",
    "  - Per stage\n",
    "- Correctness of exercise\n",
    "  - Per challenge\n",
    "  - Per student\n",
    "- Number of stages taken for a PRIMMDebug challenge\n",
    "  - Per exercise\n",
    "  - Per student"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Time taken (seconds)\")\n",
    "time_per_challenge_fig = px.histogram([ExerciseLogProcessor.get_time_on_exercise(exercise) for exercise in exercise_logs if hasattr(exercise,\"end_time\")], marginal=\"box\", labels={\"x\": \"Time taken (seconds)\"})\n",
    "time_per_challenge_fig.show()\n",
    "time_per_stage_fig = px.histogram([StageLogProcessor.get_time_on_stage(stage) for stage in stage_logs if StageLogProcessor.get_time_on_stage(stage) is not None], marginal=\"box\", labels={\"x\": \"Time taken (seconds)\"})\n",
    "time_per_stage_fig.show()\n",
    "\n",
    "print(\" Correctness of PRIMMDebug challenges:\")\n",
    "print(f\"- Per PRIMMDebug challenge\")\n",
    "print(f\"- Per student\")\n",
    "\n",
    "print(\" Number of stages taken on a PRIMMDebug challenge:\")\n",
    "stages_per_challenge_fig = px.histogram([len(exercise.stage_logs) for exercise in exercise_logs], marginal=\"box\", labels={\"x\": \"Number of stages\"})\n",
    "stages_per_challenge_fig.show()\n",
    "#TODO: Segregate by each specific challenge (and student?)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise Log Stats\n",
    "Placeholder for exercise log stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_time: float = sum([ExerciseLogProcessor.get_time_on_exercise(exercise_log) for exercise_log in exercise_logs])\n",
    "print(f\"Total time on PRIMMDebug exercises: {datetime.timedelta(seconds=total_time)}\")\n",
    "\n",
    "final_program_states: list[bool] = [ExerciseLogProcessor.is_final_program_erroneous(exercise) for exercise in exercise_logs]\n",
    "successful_final_program_states: list[bool] = [final_program_state for final_program_state in final_program_states if final_program_state]\n",
    "proportion_successful_final_program_states: float = (len(successful_final_program_states) / len(final_program_states)) * 100\n",
    "print(f\"Proportion of PRIMMDebug challenges where last program run successfully executed: {proportion_successful_final_program_states:.2f}%\")\n",
    "\n",
    "print(\"Time spent focused on PRIMMDebug window per exercise\")\n",
    "time_spent_focused: list[float] = [ExerciseLogProcessor.get_time_focused(exercise) for exercise in exercise_logs]\n",
    "time_spent_focused_fig = px.histogram(time_spent_focused, marginal=\"box\", labels={\"x\": \"100% Time spent focused on PRIMMDebug window\"})\n",
    "time_spent_focused_fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Written Responses\n",
    "\n",
    "For now, just group written responses by stage name and investigate them. Also get some stats on written responses for context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import enchant\n",
    "\n",
    "from save_logs import *\n",
    "\n",
    "save_written_responses(exercise_logs)\n",
    "\n",
    "#Proprtion of reflections that contain do not contain at least one valid English word\n",
    "dict = enchant.Dict(\"en_GB\")\n",
    "written_responses = ExerciseLogProcessor.get_written_response_data(exercise_logs)\n",
    "print([response[3] for response in written_responses])\n",
    "\n",
    "#Proportion of inspect the code stages containing written responses (should be modified to \"including at least one valid word\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
