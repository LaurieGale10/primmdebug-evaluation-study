{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PRIMMDebug Log Data Analaysis Notebook\n",
    "This notebook displays all of the analysis of the log data that took place in the PRIMMDebug initial research paper.\n",
    "\n",
    "The log data was collected from five schools between December 2024-February 2025. It is divided into the following sections:\n",
    "1. **Summary statistics:** ...\n",
    "2. **Establishing variables:**...\n",
    "3. **Visualisation of variables:**...\n",
    "4. **Students' written responses:**...\n",
    "\n",
    "All you need to do is run the notebooks in order and the statistics that appear in the paper will be displayed. If there are any issues, please report them in the [Issues section of the GitHub repository](https://github.com/LaurieGale10/primmdebug-log-data-analysis/issues).\n",
    "\n",
    "Before we run anything else, let's first import all of the necessary files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from classes.ExerciseLog import ExerciseLog\n",
    "from classes.StageLog import StageLog\n",
    "from classes.StudentId import StudentId\n",
    "from classes.processors.ExerciseLogProcessor import ExerciseLogProcessor\n",
    "\n",
    "from fetch_log_from_firebase import *\n",
    "from fetch_logs_from_file import fetch_data_from_json\n",
    "\n",
    "stage_logs: list[StageLog] = parse_stage_logs(fetch_data_from_json(\"data/stage_logs\"))\n",
    "exercise_logs: list[ExerciseLog] = [exercise_log for exercise_log in parse_exercise_logs(stage_logs, fetch_data_from_json(\"data/exercise_logs\")) if len(exercise_log.stage_logs) > 0] #Cleaning should be done in parsing rather than here\n",
    "student_ids: list[StudentId] = parse_student_ids(fetch_data_from_json(\"data/student_ids\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary Statistics\n",
    "\n",
    "This data displays the following summary statistics to give information into the scale of the data we collected. We report below on:\n",
    "- Number of exercises (that contain at least one completed PRIMMDebug stage)\n",
    "  - Successful\n",
    "  - Unsuccessful\n",
    "  - Completed\n",
    "- Number of PRIMMDebug stages.\n",
    "- Number of students\n",
    "- Time of data collection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of attempted PRIMMDebug challenges: 426\n",
      "- Number of PRIMMDebug challenges where students reported successfully resolving the error they contained: 0\n",
      "- Number of PRIMMDebug challenges where students did not report successfully resolving the error they contained: 0\n",
      "- Number of entirely completed PRIMMDebug challenges (where students reached the Make stage of PRIMMDebug): 5\n",
      "\n",
      "Final stage of challenge attempts:\n",
      "{'find': 65, 'test': 202, 'fix': 18, 'spot': 13, 'run': 25, 'predict': 5, 'inspect': 3, 'modify': 5}\n",
      "\n",
      "Number of completed PRIMMDebug stages: 3892\n",
      "- Number of these containing written responses from students: \n",
      "\n",
      "Number of participating students: 139\n",
      "- Gender split (self-reported):\n",
      "{'Female': 0, 'Male': 0, 'Non-binary': 0, 'Other': 0, 'Prefer not to say': 0}\n",
      "- Year group split (self-reported):\n",
      "{'Year 7': 0, 'Year 8': 0, 'Year 9': 0, 'Year 10': 0, 'Year 11': 0}\n",
      "- Number of students per school:\n",
      "{'School A': 0, 'School B': 0, 'School C': 0, 'School D': 0, 'School E': 0}\n",
      "\n",
      "Attempted challenges per student:\n",
      "dict_values([12, 8, 9, 12, 2, 6, 12, 16, 8, 5, 21, 10, 3, 5, 21, 2, 12, 11, 9, 7, 3, 5, 13, 10, 6, 8, 8, 5, 11, 5, 10, 5, 15, 11, 5, 8, 8, 7, 10, 8, 5, 1, 8, 4, 5, 7, 3, 3, 4, 3, 5, 4, 6, 1, 4, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1])\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of attempted PRIMMDebug challenges: {len(exercise_logs)}\")\n",
    "\n",
    "number_successful_exercises: int = 0\n",
    "print(f\"- Number of PRIMMDebug challenges where students reported successfully resolving the error they contained: {number_successful_exercises}\")\n",
    "\n",
    "number_unsuccessful_exercises: int = 0\n",
    "print(f\"- Number of PRIMMDebug challenges where students did not report successfully resolving the error they contained: {number_unsuccessful_exercises}\")\n",
    "\n",
    "number_completed_exercises: int = len([ExerciseLogProcessor.get_last_stage(exercise_log).stage_name for exercise_log in exercise_logs if ExerciseLogProcessor.get_last_stage(exercise_log) is not None and ExerciseLogProcessor.get_last_stage(exercise_log).stage_name == \"modify\"])\n",
    "print(f\"- Number of entirely completed PRIMMDebug challenges (where students reached the Make stage of PRIMMDebug): {number_completed_exercises}\\n\")\n",
    "\n",
    "from collections import Counter\n",
    "print(f\"Final stage of challenge attempts:\\n{dict(Counter([ExerciseLogProcessor.get_last_stage(exercise_log).stage_name for exercise_log in exercise_logs if ExerciseLogProcessor.get_last_stage(exercise_log) is not None]))}\\n\")\n",
    "\n",
    "print(f\"Number of completed PRIMMDebug stages: {len(stage_logs)}\")\n",
    "print(f\"- Number of these containing written responses from students: \\n\")\n",
    "\n",
    "print(f\"Number of participating students: {len(student_ids)}\")\n",
    "\n",
    "from constants import *\n",
    "\n",
    "print(f\"- Gender split (self-reported):\\n{get_gender_split()}\")\n",
    "print(f\"- Year group split (self-reported):\\n{get_year_group_split()}\")\n",
    "print(f\"- Number of students per school:\\n{get_school_split()}\\n\")\n",
    "\n",
    "exercises_per_student: dict[str, int] = {}\n",
    "for exercise in exercise_logs:\n",
    "    student_id: str = exercise.student_id\n",
    "    exercises_per_student[student_id] = exercises_per_student.get(student_id) + 1 if student_id in exercises_per_student else 1\n",
    "print(f\"Attempted challenges per student:\\n{exercises_per_student.values()}\") #To be tabulated or visualised\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Establishing Variables\n",
    "Now we move onto introducing the variables that underpin our log data analysis. These include:\n",
    "- Time taken\n",
    "  - Per challenge attempt\n",
    "  - Per stage\n",
    "- Correctness of exercise\n",
    "  - Per challenge\n",
    "  - Per student\n",
    "- Number of stages taken for a PRIMMDebug challenge\n",
    "  - Per exercise\n",
    "  - Per student"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Time taken\")\n",
    "print(f\"- Per PRIMMDebug challenge\")\n",
    "print(f\"- Per PRIMMDebug stage\")\n",
    "      \n",
    "print(\" Correctness of PRIMMDebug challenges:\")\n",
    "print(f\"- Per PRIMMDebug challenge\")\n",
    "print(f\"- Per student\")\n",
    "\n",
    "print(\" Number of stages taken on a PRIMMDebug challenge:\")\n",
    "print(f\"- Per PRIMMDebug challenge\")\n",
    "print(f\"- Per student\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
